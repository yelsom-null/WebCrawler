<h1>Web Crawler Project</h1>

<h2>To Do's</h2>
<ul>
<li>Add Dependencies [x]</li> 
    <ul><li>JSDOM</li></ul>
<li>Create Function to Parse HTML and return links [x]</li>
<li>Create Function to Crawl each link [x]</li>
</ul>
<ul>
<h2>Ideas for extending the project</h2>
<li>Make the script run on a timer and deploy it to a server. Have it email you every so often with a report</li>
<li>Add more robust error checking so that you can crawl larger sites without issues</li>
<li>Count external links, as well as internal links, and add them to the report</li>
<li>Save the report as a CSV spreadsheet rather than printing it to the console</li>
<li>Use a graphics library to create an image that shows the links between the pages as a graph visualization</li>
</ul>


    
    
    
    
    